{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a1aa1a-5375-4903-a54d-ae97273c6482",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tanikina/low-resource-nlp-lab/blob/main/notebooks/PEFT_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8d023-0317-4e9a-b53b-4e1848a7d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install datasets\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7ae30e-82f6-4f76-98f7-716bf4064052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25cac12-c3de-4e01-9969-cd036104fefb",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Dataset Preparation\n",
    "**Robot-Assisted Disaster Response** dataset consists of conversations recorded during the training sessions in the emergency response domain. The conversations are typically between several operators controlling the robots, a team leader and a mission commander. Each dialogue turn is annotated with one of the following intent labels:\n",
    "\n",
    "| label | meaning | train | percentage | example |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | disconfirm | 35 | 1.3% | `Ist negativ, noch nicht.` |\n",
    "| | | | | Is negative, not yet. |\n",
    "| 1 | order | 216 | 8.3% | `F√ºr Sie Erkundungsauftrag: Gesamt√ºberblick √ºber die Einsatzstelle. Kommen.` |\n",
    "| | | | | For you, reconnaissance assignment: overall overview of the site. Come in. |\n",
    "| 2 | info_provide | 979 | 37.5% | `Ich verlasse das Erdgeschoss und gehe ins erste Obergeschoss.` |\n",
    "| | | | | I leave the ground floor and go to the first floor. |\n",
    "| 3 | info_request | 238 | 9.1% | `Frage: Erkundungsergebnis aus der √∂stlichen Seite des Geb√§udes, kommen.` |\n",
    "| | | | | Question: Exploration results from the eastern side of the building, come in. |\n",
    "| 4 | call | 487 | 18.7% | `RobLW an Zugf√ºhrer, kommen.` |\n",
    "| | | | | RobLW to platoon commander, come in. |\n",
    "| 5 | call_response | 370 | 14.2% | `Ja, hier ist Zugf√ºhrer, kommen.` |\n",
    "| | | | | Yes, here is the platoon commander, come in. |\n",
    "| 6 | other | 43 | 1.7% | `Einen Augenblick, ich melde mich gleich.` |\n",
    "| | | | | Just a moment, I will let you know soon. |\n",
    "| 7 | confirm | 242 | 9.3% | `Ein Lagebild von oben, komplette Lage, und ein Lagebild zwischen den beiden T√ºren, verstanden.` |\n",
    "| | | | | A picture from above, complete setting, and a picture between both doors, understood. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f79c3d-f407-4942-9f9c-0996768639d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Defining the task and hyperparameters\n",
    "task = \"intent_classification\"\n",
    "model_name = \"xlm-roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "encode_prev_turn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8766dd-65fb-42e2-93cc-cdf469e43874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the speaker information with the input text\n",
    "def add_speaker(example):\n",
    "    example[\"text\"] = example[\"speaker\"] + \" - \" + example[\"text\"]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d814068a-60d3-4c06-9464-d83c384257fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': 2, 'input_ids': [0, 345, 27816, 20, 345, 27816, 1256, 23752, 38953, 13, 4, 1439, 108879, 198, 404, 186, 169846, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['UAV - UAV hat Softwareprobleme, wir versuchen es zu beheben.']\n",
      "{'labels': 2, 'input_ids': [0, 20602, 20, 823, 4, 493, 43254, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['TL - Ja, verstanden.']\n",
      "{'labels': 1, 'input_ids': [0, 20602, 20, 40787, 111697, 4, 2964, 4077, 599, 38250, 87523, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['TL - Bitte melden, wenn wieder einsatzbereit.']\n"
     ]
    }
   ],
   "source": [
    "# Defining the tokenizer and pre-processing the data\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data = datasets.load_dataset(\"DFKI/radr_intents\")\n",
    "# Preparing the training data\n",
    "train_task_dataset = train_task_dataset = data[\"train\"] # datasets.Dataset.from_csv(\"radr_intents/train.csv\")\n",
    "train_task_dataset = train_task_dataset.map(add_speaker)\n",
    "train_task_dataset = train_task_dataset.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)\n",
    "train_task_dataset = train_task_dataset.rename_column(\"label\",\"labels\")\n",
    "train_task_dataset = train_task_dataset.remove_columns(['id', 'speaker', 'text'])\n",
    "\n",
    "# Preparing the validation data\n",
    "dev_task_dataset = dev_task_dataset = data[\"validation\"] # datasets.Dataset.from_csv(\"radr_intents/dev.csv\")\n",
    "dev_task_dataset = dev_task_dataset.map(add_speaker)\n",
    "dev_task_dataset = dev_task_dataset.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)\n",
    "dev_task_dataset = dev_task_dataset.rename_column(\"label\",\"labels\")\n",
    "dev_task_dataset = dev_task_dataset.remove_columns(['id', 'speaker', 'text'])\n",
    "\n",
    "# Printing some examples\n",
    "for sample_i, sample in enumerate(dev_task_dataset):\n",
    "    if sample_i > 2:\n",
    "        break\n",
    "    print(sample)\n",
    "    print(tokenizer.batch_decode([sample[\"input_ids\"][:30]], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2d0e0-5ec8-4955-8990-28dbe5dd0814",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cef6109-448a-44fb-ba94-5e2845e53ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptEncoderConfig,\n",
    "    LoraConfig,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "task = \"radr_intents\"\n",
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa0a7d-ea0c-45df-997e-be1425906517",
   "metadata": {},
   "source": [
    "Here we can choose between `PromptEncoderConfig` for P-tuning introduced in [GPT Understands, Too (Liu et al., 2021)](https://www.semanticscholar.org/paper/GPT-Understands%2C-Too-Liu-Zheng/bc37c6bdb8f39929a58b30464f72d6aa46cddc17) and `LoraConfig` for [LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)](https://www.semanticscholar.org/paper/LoRA%3A-Low-Rank-Adaptation-of-Large-Language-Models-Hu-Shen/a8ca46b171467ceb2d7652fbfb67fe701ad86092)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0d7c40-2811-4c9e-8e13-d9527068d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=30, encoder_hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b052c-e38e-4107-8981-bac78cba8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=16,\n",
    "            bias=\"none\",\n",
    "            task_type=\"SEQ_CLS\",\n",
    "            target_modules=[\"key\", \"query\", \"value\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92808b06-5c64-4144-867d-2d54dcc73f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 833,800 || all params: 278,883,600 || trainable%: 0.2989777814113128\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=8, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddbfca0-e0e5-4ca9-95ca-c13a9f128072",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364c5e1-7f04-4402-afee-1d31d12db507",
   "metadata": {},
   "source": [
    "### üöÄ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923d5222-4866-4c2d-8610-787a4b4437b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"roberta-base-peft\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    full_determinism=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_task_dataset,\n",
    "    eval_dataset=dev_task_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6debcb-db00-43e6-8bec-72370a00793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3280' max='3280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3280/3280 03:30, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.769225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.761213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.809234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.780500</td>\n",
       "      <td>1.827829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.780500</td>\n",
       "      <td>1.549241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.780500</td>\n",
       "      <td>1.346341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.523500</td>\n",
       "      <td>1.107880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.523500</td>\n",
       "      <td>1.147788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.523500</td>\n",
       "      <td>1.077515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.196300</td>\n",
       "      <td>1.099513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.196300</td>\n",
       "      <td>0.974644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.196300</td>\n",
       "      <td>1.053547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.038000</td>\n",
       "      <td>1.014303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.038000</td>\n",
       "      <td>0.955784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.038000</td>\n",
       "      <td>0.929525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.965591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.952893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.921041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>0.894567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>0.877211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3280, training_loss=1.2007528537657204, metrics={'train_runtime': 210.9168, 'train_samples_per_second': 247.491, 'train_steps_per_second': 15.551, 'total_flos': 885640102603776.0, 'train_loss': 1.2007528537657204, 'epoch': 20.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0579bb-acea-4272-93d0-d8d4f7faf9dd",
   "metadata": {},
   "source": [
    "### ‚úÖ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc360a2d-78e5-40c0-8042-abd1e0ceab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5557, -1.8112, -2.0377, -0.0248,  7.3617,  0.9375, -0.8120, -2.7155],\n",
      "        [ 0.2110,  1.4479,  3.4419,  3.2218, -5.0600, -3.8530, -0.5526,  0.1037],\n",
      "        [-0.8891,  1.6071,  1.1785,  5.2296, -3.2375, -3.1483, -0.1494, -1.5106]],\n",
      "       device='cuda:0')\n",
      "UAV - UAV f√ºr Teamleader >>> call\n",
      "UGV 2 - Wir haben einen Kanister im Ergeschoss gefunden >>> info_provide\n",
      "TL - Was ist deine aktuelle Position? >>> info_request\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: 'disconfirm', 1: 'order', 2: 'info_provide', 3: 'info_request', 4: 'call', 5: 'call_response', 6: 'other', 7: 'confirm'}\n",
    "texts = [\"UAV - UAV f√ºr Teamleader\", \"UGV 2 - Wir haben einen Kanister im Ergeschoss gefunden\", \"TL - Was ist deine aktuelle Position?\"]\n",
    "inputs = tokenizer(texts, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "    print(outputs)\n",
    "    labels = [id2label[label] for label in torch.argmax(outputs, dim=-1).tolist()]\n",
    "    for text, label in zip(texts, labels):\n",
    "        print(text, \">>>\", label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
